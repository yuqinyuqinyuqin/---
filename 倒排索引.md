
**全文检索(Full-text Search)**：即先建立索引，再对索引进行搜索（倒排索引）。索引是从非结构化数据中提取出之后重新组织的信息。

构建倒排索引的几个主要步骤：
(1) 收集待建索引的文档；
(2) 对这些文档中的文本进行词条化；
(3) 对第2步产生的词条进行语言学预处理，得到**词项**；
(4) 根据**词项**对所有文档建立索引。 



![lucene的一般过程.png](https://segmentfault.com/img/remote/1460000021695249)

全文检索大体分两个过程，**索引创建(Indexing)和搜索索引(Search)**。

- 索引创建：将现实世界中所有的结构化和非结构化数据提取信息，创建索引的过程。
- 搜索索引：就是得到用户的查询请求，搜索创建的索引，然后返回结果的过程。

## 索引创建

全文检索的索引创建过程一般有以下几步：

#### 第一步：一些要索引的原文档(Document)。

为了方便说明索引创建过程，这里特意用两个文件为例：

- 文件一：Students should be allowed to go out with their friends, but not allowed to drink beer.
- 文件二：My friend Jerry went to school to see his students but found them drunk which is not allowed.

#### 第二步：将原文档传给分词组件(Tokenizer)。

**将文档分成一个一个单独的单词。去除标点符号。去除停词(Stop word)。

1. **变为小写(Lowercase)。**
2. **将单词缩减为词根形式，如"cars"到"car"等。这种操作称为：stemming。** “缩减 采取某种固定的算法来做这种缩减，如去除“s”，去除“ing”加“e”，将“ational”变为“ate”，将“tional”变为“tion”。
3. **将单词转变为词根形式，如"drove"到"drive"等。这种操作称为：lemmatization。**“转变”的方式 采用保存某种字典的方式做这种转变。比如字典中有“driving”到“drive”，“drove”到“drive”，“am, is, are”到“be”的映射，做转变时，只要查字典就可以了。
4** 二元词索引**

处理短语查询的一个办法就是将文档中每个接续词对看成一个短语。例如，文本 Friends,Romans, Countrymen 会产生如下的二元接续词对<Friends,Romans>,<Romans, Countrymen>

如果索引中包含变长的词序列，通常就称为短语索引（phrase index）。实际上，利用二元词索引来处理单个词的查询不太方便（必须要扫描整个词汇表来发现包含该查询词的二元词），因此同时还需要有基于单个词的索引。尽管总有可能得到错误的匹配结果，但是在长度为3或者更长的索引短语上发生匹配错误的可能性实际上却很小。然而在另一方面，存储更长的短语很可能会大大增加词汇表的大小。穷尽所有长度超过2的短语并维护其索引绝对是一件令人生畏的事情，即使只穷尽所有的二元词也会大大增加词汇表的大小。

为处理短语查询，仍然需要访问各个词项的倒排记录表。像以往一样，这里可以采用最小文档频率优先的策略，从而可以限制后续合并的候选词项的数目。在合并操作中，同样可以采用前面提到的各种技术来实现，**但是这里不只是简单地判断两个词项是否出现在同一文档中，而且还需要检查它们出现的位置关系和查询短语的一致性。这就需要计算出词之间的偏移距离。**
基于上面谈到的原因，二元词索引并非标准的解决方案。实际中更常用的一种方式是采用所谓的位置信息索引（positional index，简称位置索引）。在这种索引中，对每个词项，以如下方式存储倒排记录

![图片](https://mmbiz.qpic.cn/mmbiz_png/5fknb41ib9qEkpef92EuDauK6TMoQeqAxEl07VRGugzdlibkEfdKA3wAxnYmhDYAiaQnVib682hxZ93CWMmFK5HvxQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

**单词be的文档频率是178239，在文档1中出现2次，位置分别是17、25。**

现在用户应该只想搜出文档 2 出来. 基于"位置信息索引"方式, 我们可以做到这一点.这种搜索方法类似于**k词近邻搜索 —— a /k b**

这里，/k 意味着“ 从左边或右边相距在 k 个词之内，若k=1，则意味着a、b相邻” 。很显然，位置索引能够用于邻近搜索，而二元词索引则不能。

有了这个索引存储结构, 要找出不同的短语就比较容易了, 比如用户想搜索"boy friend", 就可以转化成 boy /1 friend 即可以完成要求

```
## 索引查询

Elasticsearch 执行上面 `match` 查询的步骤是：

1. *检查字段类型* 。

   标题 `title` 字段是一个 `string` 类型（ `analyzed` ）已分析的全文字段，这意味着查询字符串本身也应该被分析。

2. *分析查询字符串* 。

   将查询的字符串 `QUICK!` 传入标准分析器中，输出的结果是单个项 `quick` 。因为只有一个单词项，所以 `match` 查询执行的是单个底层 `term` 查询。

3. *查找匹配文档* 。

   用 `term` 查询在倒排索引中查找 `quick` 然后获取一组包含该项的文档，本例的结果是文档：1、2 和 3 。

4. *为每个文档评分* 。

   用 `term` 查询计算每个文档相关度评分 `_score` ，这是种将词频（term frequency，即词 `quick` 在相关文档的 `title` 字段中出现的频率）和反向文档频率（inverse document frequency，即词 `quick` 在所有文档的 `title` 字段中出现的频率），以及字段的长度（即字段越短相关度越高）相结合的计算方式。

1. 计算权重(Term weight)的过程。

对于程序员本身来说，这项技术掌握越深越好（掌握越深说明花时间看的越多，tf越大），找工作时越有竞争力。然而对于所有程序员来说，这项技术懂得的人越少越好（懂得的人少df小），找工作越有竞争力

2.判断Term之间的关系从而得到文档相关性的过程，也即向量空间模型的算法(VSM)。

我们把文档看作一系列词(Term)，每一个词(Term)都有一个权重(Term weight)，不同的词(Term)根据自己在文档中的权重来影响文档相关性的打分计算。

于是我们把所有此文档中词(term)的权重(term weight) 看作一个向量。

Document = {term1, term2, …… ,term N}

Document Vector = {weight1, weight2, …… ,weight N}

同样我们把查询语句看作一个简单的文档，也用向量来表示。

Query = {term1, term 2, …… , term N}

Query Vector = {weight1, weight2, …… , weight N}

我们把所有搜索出的文档向量及查询向量放到一个N维空间中，每个词(term)是一维

![image-20201219170829715](C:\Users\yuqin03\AppData\Roaming\Typora\typora-user-images\image-20201219170829715.png)



https://tech.youzan.com/search-engine1/ ES 索引构建  

